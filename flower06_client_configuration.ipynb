{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "msdrsEsNEWdC"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedAdagrad\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_cEjGLmFf17",
        "outputId": "a82d28f8-6676-4a77-87dd-9432357f6173"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.18.0 / PyTorch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PARTITIONS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(\n",
        "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "xeUz09BGFib-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "Vn3FAIkJFjtU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, pid, net, trainloader, valloader):\n",
        "        self.pid = pid  # partition ID of a client\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.pid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.pid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.pid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = Net().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
        "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "fVpGhxZqFlbi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if server_round < 2 else 2,\n",
        "    }\n",
        "    return config"
      ],
      "metadata": {
        "id": "b_AkJh3tGoJi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The `evaluate` function will be called by Flower after every round\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: NDArrays,\n",
        "    config: Dict[str, Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "    net = Net().to(DEVICE)\n",
        "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "8zcTaVANIb_T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "params = get_parameters(Net())"
      ],
      "metadata": {
        "id": "jExhKlifFmsb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    # Create FedAvg strategy\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=1,\n",
        "        fraction_evaluate=1,\n",
        "        min_fit_clients=5,\n",
        "        min_evaluate_clients=5,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "        evaluate_fn=evaluate, #server side evaluation\n",
        "        on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=3)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "JfEJDol2H7iC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the resources each of your clients need\n",
        "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": None}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_PARTITIONS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lebIaGO7IHia",
        "outputId": "e3cb3c8a-1ec1-416f-834e-020b7d1faae1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[36m(pid=5501)\u001b[0m 2025-05-03 17:15:43.160676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=5501)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=5501)\u001b[0m E0000 00:00:1746292543.205684    5501 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=5501)\u001b[0m E0000 00:00:1746292543.217909    5501 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07210520164966583, {'accuracy': 0.1001}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07210520164966583 / accuracy 0.1001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.061447374522686005, accuracy 0.27175\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.06143762171268463, accuracy 0.271875\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.06176060065627098, accuracy 0.263875\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.06107587367296219, accuracy 0.28275\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.06209059804677963, accuracy 0.2615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.059910904765129086, {'accuracy': 0.3235}, 59.63978205000012)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.059910904765129086 / accuracy 0.3235\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.053721074014902115, accuracy 0.367625\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.0495319738984108, accuracy 0.4175\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.05344878137111664, accuracy 0.36825\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.049050748348236084, accuracy 0.424625\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.054064616560935974, accuracy 0.361375\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.049916479736566544, accuracy 0.4035\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.053322527557611465, accuracy 0.37075\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.04887755215167999, accuracy 0.427875\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.05379311367869377, accuracy 0.36775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.04987408593297005, accuracy 0.417625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.047630358231067656, {'accuracy': 0.4421}, 162.98093490099996)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.047630358231067656 / accuracy 0.4421\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.048205893486738205, accuracy 0.43025\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.0456092469394207, accuracy 0.468625\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.04771515727043152, accuracy 0.442875\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.0451936312019825, accuracy 0.472\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.048412732779979706, accuracy 0.4205\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.04570765048265457, accuracy 0.465625\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.047642290592193604, accuracy 0.439125\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.04479847103357315, accuracy 0.47675\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 1: train loss 0.04799629747867584, accuracy 0.432875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m Epoch 2: train loss 0.045354537665843964, accuracy 0.4765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.04427281839847565, {'accuracy': 0.4838}, 265.80321815499997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.04427281839847565 / accuracy 0.4838\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5501)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 277.84s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06072934459447861\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04856152304410935\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.04485790077447891\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.07210520164966583\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.059910904765129086\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.047630358231067656\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.04427281839847565\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1001), (1, 0.3235), (2, 0.4421), (3, 0.4838)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1a3y0pfYIIlf"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}