{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbDF9llk5tQe",
        "outputId": "fa7b9ce9-e4c4-433c-9239-b0e5c610dd74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.9.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedAdagrad\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epOk91uC6vAu",
        "outputId": "56f138ab-f2e1-4ca2-a1ce-7d6d784cae11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.18.0 / PyTorch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PARTITIONS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(\n",
        "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "H8X3Rd957nZ4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "xWjmrO0L718e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id, net, trainloader, valloader):\n",
        "        self.partition_id = partition_id\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Read the node_config to fetch data partition associated to this node\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "\n",
        "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
        "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "KwmgjumL74wv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "params = get_parameters(Net())"
      ],
      "metadata": {
        "id": "UA4tBa4z76zX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The `evaluate` function will be called by Flower after every round\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: NDArrays,\n",
        "    config: Dict[str, Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "    net = Net().to(DEVICE)\n",
        "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "ALTWMznd8Cgv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server-side parameter **evaluation**\n",
        "\n",
        "Flower can evaluate the aggregated model on the server-side or on the client-side. Client-side and server-side evaluation are similar in some ways, but different in others.\n",
        "\n",
        "**Centralized Evaluation** (or *server-side evaluation*) is conceptually simple: it works the same way that evaluation in centralized machine learning does. If there is a server-side dataset that can be used for evaluation purposes, then that's great. We can evaluate the newly aggregated model after each round of training without having to send the model to clients. We're also fortunate in the sense that our entire evaluation dataset is available at all times.\n",
        "\n",
        "**Federated Evaluation** (or *client-side evaluation*) is more complex, but also more powerful: it doesn't require a centralized dataset and allows us to evaluate models over a larger set of data, which often yields more realistic evaluation results. In fact, many scenarios require us to use **Federated Evaluation** if we want to get representative evaluation results at all. But this power comes at a cost: once we start to evaluate on the client side, we should be aware that our evaluation dataset can change over consecutive rounds of learning if those clients are not always available. Moreover, the dataset held by each client can also change over consecutive rounds. This can lead to evaluation results that are not stable, so even if we would not change the model, we'd see our evaluation results fluctuate over consecutive rounds.\n",
        "\n",
        "We've seen how federated evaluation works on the client side (i.e., by implementing the `evaluate` method in `FlowerClient`). Now let's see how we can evaluate aggregated model parameters on the server-side:"
      ],
      "metadata": {
        "id": "6iVFL6KA8HUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    # Create the FedAvg strategy\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=1,\n",
        "        fraction_evaluate=1,\n",
        "        min_fit_clients=5,\n",
        "        min_evaluate_clients=5,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "        evaluate_fn=evaluate,  # Pass the evaluation function\n",
        "    )\n",
        "    # Configure the server for 3 rounds of training\n",
        "    config = ServerConfig(num_rounds=3)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "4syF-KTv8FQv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": None}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_PARTITIONS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcE0EGpQ8Urf",
        "outputId": "c742986e-848d-4f82-803b-aa2810542fbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[36m(pid=5182)\u001b[0m 2025-05-03 16:24:22.963286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=5182)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=5182)\u001b[0m E0000 00:00:1746289463.198262    5182 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=5182)\u001b[0m E0000 00:00:1746289463.227014    5182 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07216868712902069, {'accuracy': 0.0615}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07216868712902069 / accuracy 0.0615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.061832185834646225, accuracy 0.26525\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.061396535485982895, accuracy 0.27975\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.06178712844848633, accuracy 0.26125\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.06135924533009529, accuracy 0.275125\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.062053706496953964, accuracy 0.261875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.05965306313037872, {'accuracy': 0.3536}, 66.95670645299992)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.05965306313037872 / accuracy 0.3536\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.05342862010002136, accuracy 0.36825\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.053195852786302567, accuracy 0.370875\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.05401067063212395, accuracy 0.359125\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.05330224707722664, accuracy 0.375375\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.053560275584459305, accuracy 0.374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.04942217069864273, {'accuracy': 0.4264}, 147.5841882499999)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.04942217069864273 / accuracy 0.4264\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.049831755459308624, accuracy 0.41375\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.04969844967126846, accuracy 0.419\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.05007021501660347, accuracy 0.40975\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.049229834228754044, accuracy 0.419375\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m Epoch 1: train loss 0.04988604411482811, accuracy 0.421125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.04650962634086609, {'accuracy': 0.4575}, 222.536352159)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.04650962634086609 / accuracy 0.4575\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5182)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 239.19s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06022637792825698\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.050080990052223204\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.047179259955883034\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.07216868712902069\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.05965306313037872\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04942217069864273\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.04650962634086609\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.0615), (1, 0.3536), (2, 0.4264), (3, 0.4575)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGiYF5oq8an5"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}