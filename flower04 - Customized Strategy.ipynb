{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rPz_G14osgfj"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedAdagrad\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ],
      "metadata": {
        "id": "cNtvW-9Rs91A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28aa6038-72bf-42cd-ffe1-a77e00944de3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.18.0 / PyTorch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PARTITIONS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(\n",
        "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "oLUYHIn2tvL0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader, valloader, testloader = load_datasets(partition_id=0, num_partitions=NUM_PARTITIONS)  # Assuming partition_id=0"
      ],
      "metadata": {
        "id": "h6ED9XegtwGo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwfEsU2cuIOe",
        "outputId": "167afe17-8105-419e-bc10-e0dc8ce2eeb6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader.batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcMGoMnUu0_G",
        "outputId": "85faf488-480a-40e4-c1d8-28a993fa4f6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader.dataset[0]['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsDj_leC3Nxg",
        "outputId": "9d92b0c5-a271-4155-c75f-cf9fb9f53c09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "Ju0HI50a3Tlc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id, net, trainloader, valloader):\n",
        "        self.partition_id = partition_id\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Read the node_config to fetch data partition associated to this node\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "\n",
        "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
        "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "iTvj5pw_3ohm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "params = get_parameters(Net())"
      ],
      "metadata": {
        "id": "WvRMQIVx3o-X"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    # Create FedAdagrad strategy\n",
        "    strategy = FedAdagrad(\n",
        "        fraction_fit=0.3,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "    )\n",
        "    # Configure the server for 3 rounds of training\n",
        "    config = ServerConfig(num_rounds=3)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "# Specify the resources each of your clients need\n",
        "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": None}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
        "\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_PARTITIONS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDzED8Y-3yUl",
        "outputId": "bd54ca48-eb4c-4df9-a76f-273ef55e5493"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n",
            "\u001b[36m(pid=4049)\u001b[0m 2025-05-06 18:58:46.872039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=4049)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=4049)\u001b[0m E0000 00:00:1746557926.939740    4049 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=4049)\u001b[0m E0000 00:00:1746557926.960771    4049 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.0657043606042862, accuracy 0.21\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.06517796218395233, accuracy 0.22125\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 9] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.0649188980460167, accuracy 0.2345\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 8] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.9227942824363708, accuracy 0.26425\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.8870652914047241, accuracy 0.2855\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 8] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.9797358512878418, accuracy 0.2735\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 9] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.07398809492588043, accuracy 0.1805\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.07362991571426392, accuracy 0.1745\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 8] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m Epoch 1: train loss 0.07377487421035767, accuracy 0.18075\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=4049)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 121.30s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 7.65021859741211\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.18659535026550292\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.23395562871297204\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LX_vQY2m4trF"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}