{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qq54XDlvwWS",
        "outputId": "4c6ed153-390b-4a5b-a4b5-4335a640d968"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.9.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Device Configuration\n",
        "import torch\n",
        "import flwr\n",
        "from datasets.utils.logging import disable_progress_bar"
      ],
      "metadata": {
        "id": "VgF7xpNyvj5a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device and constants\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73T0TdmZvnvR",
        "outputId": "e117a4de-ca2e-46cf-8093-4a02ca6c796d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.18.0 / PyTorch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to 5 clients (modified from 10)\n",
        "NUM_CLIENTS = 5\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "KOQewrUsvpUh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Neural Network Model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "fjqIJ2KQvqla"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iV0PthW4yMcZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading Functions\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from flwr_datasets import FederatedDataset"
      ],
      "metadata": {
        "id": "b4_I20bJyQGp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(partition_id: int):\n",
        "    \"\"\"Load CIFAR-10 data partitions for federated learning.\"\"\"\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": NUM_CLIENTS})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    # Create train/val for each partition and wrap it into DataLoader\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(\n",
        "        partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "    )\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "T31VNGUMyUCB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Testing Functions\n",
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")"
      ],
      "metadata": {
        "id": "5QchSaMeyXYR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "4Qdjh4HYyZ3Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Handling Utilities\n",
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UGAUXAcfybnZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    \"\"\"Set model parameters from a list of NumPy arrays.\"\"\"\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    \"\"\"Get model parameters as a list of NumPy arrays.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "C-uP3auLydq5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flower Client Definition\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Context\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "wapeonSYygsB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Client Factory Function\n",
        "def client_fn(context: Context) -> Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data partition associated with this client\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "\n",
        "    # Create and return client\n",
        "    return FlowerClient(net, trainloader, valloader).to_client()"
      ],
      "metadata": {
        "id": "ui-mncquyj-p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Federated Learning Strategy\n",
        "from flwr.server.strategy import FedAvg\n",
        "\n",
        "# Create federated learning strategy (modified for 5 clients)\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=1.0,      # Sample 100% of available clients for training\n",
        "    fraction_evaluate=1.0, # Sample 100% of available clients for evaluation\n",
        "    min_fit_clients=5,     # Never sample less than 5 clients for training\n",
        "    min_evaluate_clients=5, # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=5, # Wait until all 5 clients are available\n",
        ")"
      ],
      "metadata": {
        "id": "Ege_KbBsyoB4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Server Configuration\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "\n",
        "# Define server function\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Configure server components.\"\"\"\n",
        "    # Configure the server for 5 rounds of training\n",
        "    config = ServerConfig(num_rounds=5)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)"
      ],
      "metadata": {
        "id": "WVVSrKVwyrFZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create client and server apps\n",
        "client = ClientApp(client_fn=client_fn)\n",
        "server = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "sEWbVp0EyuVY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resource Configuration and Simulation\n",
        "from flwr.simulation import run_simulation\n",
        "\n",
        "# Specify client resources\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "# Use GPU if available\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}"
      ],
      "metadata": {
        "id": "rB-iMSRgywfJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m5Wc6kDu-rn",
        "outputId": "0c5692d6-a577-4f8d-836d-2615f25b9359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[94mDEBUG 2025-05-03 13:48:21,968\u001b[0m:     Asyncio event loop already running.\n",
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,970\u001b[0m:     Logger propagate set to False\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,970\u001b[0m:     Pre-registering run with id 16603539432482731006\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,975\u001b[0m:     Using InMemoryState\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,976\u001b[0m:     Using InMemoryState\n",
            "\u001b[92mINFO 2025-05-03 13:48:21,978\u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
            "\u001b[92mINFO 2025-05-03 13:48:21,981\u001b[0m:      \n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,983\u001b[0m:     Using InMemoryState\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,984\u001b[0m:     Registered 5 nodes\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,984\u001b[0m:     Supported backends: ['ray']\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,987\u001b[0m:     Initialising: RayBackend\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:21,990\u001b[0m:     Backend config: {'client_resources': {'num_cpus': 1, 'num_gpus': 0.0}, 'init_args': {}, 'actor': {'tensorflow': 0}}\n",
            "\u001b[92mINFO 2025-05-03 13:48:21,999\u001b[0m:      [INIT]\n",
            "\u001b[92mINFO 2025-05-03 13:48:22,002\u001b[0m:      Requesting initial parameters from one random client\n",
            "2025-05-03 13:48:26,007\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:28,651\u001b[0m:     Constructed ActorPool with: 2 actors\n",
            "\u001b[94mDEBUG 2025-05-03 13:48:28,662\u001b[0m:     Using InMemoryState\n",
            "\u001b[36m(pid=2302)\u001b[0m 2025-05-03 13:48:34.713695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=2302)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=2302)\u001b[0m E0000 00:00:1746280114.807616    2302 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=2302)\u001b[0m E0000 00:00:1746280114.832464    2302 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=2302)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[36m(pid=2301)\u001b[0m 2025-05-03 13:48:34.777780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=2301)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=2301)\u001b[0m E0000 00:00:1746280114.861771    2301 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=2301)\u001b[0m E0000 00:00:1746280114.890016    2301 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]\n",
            "Generating train split:   9%|▉         | 4700/50000 [00:00<00:01, 44721.68 examples/s]\n",
            "Generating train split:  28%|██▊       | 13800/50000 [00:00<00:00, 71276.46 examples/s]\n",
            "Generating train split:  45%|████▌     | 22500/50000 [00:00<00:00, 77625.00 examples/s]\n",
            "Generating train split:  65%|██████▍   | 32300/50000 [00:00<00:00, 85152.40 examples/s]\n",
            "Generating train split:  84%|████████▍ | 41900/50000 [00:00<00:00, 88719.88 examples/s]\n",
            "Generating train split: 100%|██████████| 50000/50000 [00:00<00:00, 84593.31 examples/s]\n",
            "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]\n",
            "Generating test split: 100%|██████████| 10000/10000 [00:00<00:00, 94037.42 examples/s]\n",
            "\u001b[92mINFO 2025-05-03 13:48:58,216\u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO 2025-05-03 13:48:58,217\u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO 2025-05-03 13:48:58,218\u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO 2025-05-03 13:48:58,221\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:48:58,221\u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO 2025-05-03 13:48:58,222\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=2301)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO 2025-05-03 13:49:38,464\u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[93mWARNING 2025-05-03 13:49:38,473\u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO 2025-05-03 13:49:38,474\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:49:58,056\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[93mWARNING 2025-05-03 13:49:58,057\u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO 2025-05-03 13:49:58,058\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:49:58,059\u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO 2025-05-03 13:49:58,059\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:50:44,407\u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:50:44,430\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:51:02,392\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:51:02,395\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:51:02,397\u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO 2025-05-03 13:51:02,399\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:51:43,737\u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:51:43,746\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:52:02,114\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:52:02,115\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:52:02,118\u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO 2025-05-03 13:52:02,121\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:52:40,234\u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:52:40,243\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:52:57,590\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:52:57,591\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:52:57,593\u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO 2025-05-03 13:52:57,594\u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:53:39,368\u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:53:39,380\u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,060\u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,062\u001b[0m:      \n",
            "\u001b[92mINFO 2025-05-03 13:53:59,063\u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,064\u001b[0m:      Run finished 5 round(s) in 300.84s\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,065\u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,066\u001b[0m:      \t\tround 1: 0.06072605152130127\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,066\u001b[0m:      \t\tround 2: 0.05049052579402923\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,067\u001b[0m:      \t\tround 3: 0.04726053508520126\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,067\u001b[0m:      \t\tround 4: 0.045147823715209964\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,068\u001b[0m:      \t\tround 5: 0.04368421720862389\n",
            "\u001b[92mINFO 2025-05-03 13:53:59,069\u001b[0m:      \n",
            "\u001b[94mDEBUG 2025-05-03 13:53:59,079\u001b[0m:     ServerApp finished running.\n",
            "\u001b[94mDEBUG 2025-05-03 13:53:59,080\u001b[0m:     ServerApp finished running.\n",
            "\u001b[94mDEBUG 2025-05-03 13:53:59,081\u001b[0m:     Triggered stop event for Simulation Engine.\n",
            "\u001b[94mDEBUG 2025-05-03 13:53:59,997\u001b[0m:     Terminated 2 actors\n",
            "\u001b[94mDEBUG 2025-05-03 13:54:01,514\u001b[0m:     Terminated RayBackend\n",
            "\u001b[94mDEBUG 2025-05-03 13:54:01,515\u001b[0m:     Stopping Simulation Engine now.\n"
          ]
        }
      ],
      "source": [
        "# Run the federated learning simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_CLIENTS,  # 5 clients\n",
        "    backend_config=backend_config,\n",
        "    verbose_logging=True,\n",
        ")"
      ]
    }
  ]
}